<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Martin Sjogard">
<meta name="dcterms.date" content="2024-07-19">

<title>Permutation-Based FWER Correction, Part 2: Background pt 2 – Martin Sjogard</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-2e5f03a80cec35ae7dc664bbc6ce041c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://code.iconify.design/iconify-icon/1.0.7/iconify-icon.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../custom.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Martin Sjogard</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-posts" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Posts</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-posts">    
        <li>
    <a class="dropdown-item" href="../../posts/quicksummaries_localspindles/ind.qmd">
 <span class="dropdown-text">Quick paper summary: Sleep spindles, motor learning and sleep-dependent memory consolidation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/kmeans-permutation/index.html">
 <span class="dropdown-text">Developing a novel cluster number determination for K-means clustering</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/power-analysis-lmm/index.html">
 <span class="dropdown-text">Power Analysis for LMMs</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/fwer-correction-part1/index.html">
 <span class="dropdown-text">FWER Correction, background pt.&nbsp;1</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/fwer-correction-part2/index.html">
 <span class="dropdown-text">FWER Correction, background pt.&nbsp;2</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-papers" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Papers</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-papers">    
        <li>
    <a class="dropdown-item" href="https://www.nature.com/articles/s41467-025-61136-y">
 <span class="dropdown-text">Hippocampal ripples predict motor learning during brief rest breaks in humans</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://www.frontiersin.org/journals/neurology/articles/10.3389/fneur.2022.871166/full">
 <span class="dropdown-text">A novel approach to estimating the cortical sources of sleep spindles using simultaneous EEG/MEG</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://www.sciencedirect.com/science/article/abs/pii/S105381191930549X">
 <span class="dropdown-text">Do the posterior midline cortices belong to the electrophysiological default-mode network?</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://onlinelibrary.wiley.com/doi/pdf/10.1002/hbm.25247">
 <span class="dropdown-text">Brain dysconnectivity relates to disability and cognitive impairment in multiple sclerosis</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/quicksummaries_localspindles/ind.qmd">
 <span class="dropdown-text">Quick paper summary: Sleep spindles, motor learning and sleep-dependent memory consolidation</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-talks" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Talks</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-talks">    
        <li>
    <a class="dropdown-item" href="../../posts/quicksummaries_localspindles/index.html">
 <span class="dropdown-text">Disrupted ipsilateral encoding of motor sequence learning in Schizophrenia: spectral and hemispheric aspects</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/quicksummaries_localspindles/index.html">
 <span class="dropdown-text">Schizophrenia patients learn normally but do not consolidate: A case for differential sleep spindle topography</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/quicksummaries_localspindles/index.html">
 <span class="dropdown-text">Sleep spindle increases follow cortical patterns of task encoding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/quicksummaries_localspindles/index.html">
 <span class="dropdown-text">Sleep spindle increases and Task learning vs Sleep-dependent memory consolidation: Two topographically distinct relationships</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/quicksummaries_localspindles/index.html">
 <span class="dropdown-text">Hippocampal ripples and memory</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/martinsjogard/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:martinsjogard@gmail.com"> <i class="bi bi-envelope" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://scholar.google.com/citations?user=F59U3gEAAAAJ&amp;hl=en"> <i class="bi bi-mortarboard-fill" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../CV_b.pdf"> <i class="bi bi-file-text" role="img">
</i> 
<span class="menu-text">CV</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-null-distribution" id="toc-the-null-distribution" class="nav-link active" data-scroll-target="#the-null-distribution">The Null Distribution</a></li>
  <li><a href="#the-distribution-under-h_0-vs.-under-h_1" id="toc-the-distribution-under-h_0-vs.-under-h_1" class="nav-link" data-scroll-target="#the-distribution-under-h_0-vs.-under-h_1">The Distribution Under <span class="math inline">\(H_0\)</span> vs.&nbsp;Under <span class="math inline">\(H_1\)</span></a></li>
  <li><a href="#definition-and-interpretation-of-the-p-value" id="toc-definition-and-interpretation-of-the-p-value" class="nav-link" data-scroll-target="#definition-and-interpretation-of-the-p-value">Definition and Interpretation of the <em>p</em>-value</a></li>
  <li><a href="#critical-values-and-the-relationship-to-p-values" id="toc-critical-values-and-the-relationship-to-p-values" class="nav-link" data-scroll-target="#critical-values-and-the-relationship-to-p-values">Critical Values and the Relationship to P-Values</a></li>
  <li><a href="#obtaining-null-distributions-analytical-vs-simulation" id="toc-obtaining-null-distributions-analytical-vs-simulation" class="nav-link" data-scroll-target="#obtaining-null-distributions-analytical-vs-simulation">Obtaining Null Distributions: Analytical vs Simulation</a></li>
  <li><a href="#example-generating-a-null-distribution-via-simulation-and-comparing-to-theory" id="toc-example-generating-a-null-distribution-via-simulation-and-comparing-to-theory" class="nav-link" data-scroll-target="#example-generating-a-null-distribution-via-simulation-and-comparing-to-theory">Example: Generating a Null Distribution via Simulation (and Comparing to Theory)</a></li>
  <li><a href="#the-role-of-null-distributions-in-multiple-comparisons" id="toc-the-role-of-null-distributions-in-multiple-comparisons" class="nav-link" data-scroll-target="#the-role-of-null-distributions-in-multiple-comparisons">The Role of Null Distributions in Multiple Comparisons</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Permutation-Based FWER Correction, Part 2: Background pt 2</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Statistics</div>
    <div class="quarto-category">Neuroscience</div>
    <div class="quarto-category">R</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Martin Sjogard </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 19, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="the-null-distribution" class="level2">
<h2 class="anchored" data-anchor-id="the-null-distribution">The Null Distribution</h2>
<p>Recall that the <strong>null hypothesis (<span class="math inline">\(H_0\)</span>)</strong> is the assumption of “no effect” or “no difference.” The <strong>null distribution</strong> is the probability distribution of the test statistic under the assumption that <span class="math inline">\(H_0\)</span> is true. In other words, it tells us how the test statistic would behave just by chance if the null hypothesis holds.</p>
<p>Formally, if <span class="math inline">\(T\)</span> is our test statistic, the null distribution is the distribution of <span class="math inline">\(T\)</span> under <span class="math inline">\(H_0\)</span>. For example:</p>
<ul>
<li><p>In the coin flip example, our test statistic was the number of heads in 20 flips. Under <span class="math inline">\(H_0\)</span> (fair coin), <span class="math inline">\(T \sim \text{Binomial}(20, 0.5)\)</span>. This binomial distribution is the null distribution of <span class="math inline">\(T\)</span>.</p></li>
<li><p>If we test for a difference in means between two large samples under <span class="math inline">\(H_0\)</span> (no true difference), the null distribution of the standardized mean difference might be approximated by a <span class="math inline">\(t\)</span>-distribution or normal distribution (depending on assumptions). For instance, in a two-sample <em>t</em>-test with equal variances, the null distribution of the <em>t</em>-statistic follows a <span class="math inline">\(t\)</span> distribution with appropriate degrees of freedom.</p></li>
<li><p>If testing a correlation’s significance, under <span class="math inline">\(H_0\)</span> (no real correlation), a suitable transform of the correlation coefficient might follow a known distribution (like a t distribution for Pearson correlation with a given sample size).</p></li>
</ul>
<p>Why is the null distribution so important? Because it provides the reference frame for significance. We compare our observed test statistic to the null distribution to see <em>how surprising</em> the observation is under <span class="math inline">\(H_0\)</span>. This comparison is at the heart of calculating p-values and determining critical values.</p>
<p>Sometimes we can derive the null distribution analytically from probability theory (as with the binomial or t distributions above). However, in many cases the null distribution might be complicated or unknown. In those situations, we often resort to <em>simulation</em> or <em>resampling</em> techniques (like permutation tests) to empirically estimate the null distribution.</p>
</section>
<section id="the-distribution-under-h_0-vs.-under-h_1" class="level2">
<h2 class="anchored" data-anchor-id="the-distribution-under-h_0-vs.-under-h_1">The Distribution Under <span class="math inline">\(H_0\)</span> vs.&nbsp;Under <span class="math inline">\(H_1\)</span></h2>
<p>It’s helpful to contrast the distribution of the test statistic assuming <span class="math inline">\(H_0\)</span> with its distribution assuming a particular alternative <span class="math inline">\(H_1\)</span>. Under <span class="math inline">\(H_0\)</span>, we know (or estimate) the null distribution. Under <span class="math inline">\(H_1\)</span>, the test statistic would typically have a different distribution – often shifted or stretched relative to the null.</p>
<p>For example, consider testing if a coin is biased toward heads. Under <span class="math inline">\(H_0\)</span> (fair coin), the number of heads in 100 flips follows a binomial distribution centered at 50. Under an <span class="math inline">\(H_1\)</span> where the coin is actually biased (say <span class="math inline">\(p=0.6\)</span> chance of heads), the distribution of heads count would center around 60. So under <span class="math inline">\(H_1\)</span>, “extreme” high values of heads (say 60 or more) are in fact likely, whereas under <span class="math inline">\(H_0\)</span> they are unlikely. This situation is depicted conceptually as two overlapping distributions: one (null) centered at 50, and another (alternative) centered at 60. A threshold (critical value) set at, say, 58 heads might have a low probability under <span class="math inline">\(H_0\)</span> (thus controlling Type&nbsp;I error) while capturing a lot of the <span class="math inline">\(H_1\)</span> distribution’s mass (thus giving decent power).</p>
<ul>
<li><p>Under <span class="math inline">\(H_0\)</span>: the statistic has some known distribution (e.g., centered at 50).</p></li>
<li><p>Under <span class="math inline">\(H_1\)</span>: the statistic’s distribution is shifted (e.g., centered at 60 if <span class="math inline">\(p=0.6\)</span>).</p></li>
</ul>
<p>The <em>power</em> of a test is the probability of correctly rejecting <span class="math inline">\(H_0\)</span> when <span class="math inline">\(H_1\)</span> is true – geometrically, it’s the area of the <span class="math inline">\(H_1\)</span> distribution that falls beyond the critical value (in the rejection region). We choose our test/critical value to balance controlling Type&nbsp;I error (false positive rate under <span class="math inline">\(H_0\)</span>) and maximizing power (true positive rate under <span class="math inline">\(H_1\)</span>). While <span class="math inline">\(H_1\)</span> can encompass many possible values (it’s often a range of scenarios), this framework helps explain why more extreme thresholds reduce false positives but also make it harder to detect real effects.</p>
<p>In practice, we usually focus on the null distribution for calculating p-values and setting up the test, since we assume <span class="math inline">\(H_0\)</span> until evidence indicates otherwise. But it’s good to remember that if there is a real effect (<span class="math inline">\(H_1\)</span> true), the test statistic is expected to deviate from the null distribution systematically.</p>
</section>
<section id="definition-and-interpretation-of-the-p-value" class="level2">
<h2 class="anchored" data-anchor-id="definition-and-interpretation-of-the-p-value">Definition and Interpretation of the <em>p</em>-value</h2>
<p>Now let’s formally define the <strong>p-value</strong>. Given an observed test statistic value (call it <span class="math inline">\(t_{\text{obs}}\)</span>), the p-value is the probability of obtaining a test statistic as extreme as (or more extreme than) <span class="math inline">\(t_{\text{obs}}\)</span> <em>assuming</em> <span class="math inline">\(H_0\)</span> is true. In formula terms:</p>
<ul>
<li>For a right-tailed test (where large values of <span class="math inline">\(T\)</span> favor <span class="math inline">\(H_1\)</span>):</li>
</ul>
<p><span class="math display">\[
\text{p-value} = \Pr_{H_0}\left(T \geq t_{\text{obs}}\right),
\]</span> the probability that <span class="math inline">\(T\)</span> is greater than or equal to the observed value, under the null distribution.</p>
<ul>
<li>For a left-tailed test (where small values favor <span class="math inline">\(H_1\)</span>):</li>
</ul>
<p><span class="math display">\[
\text{p-value} = \Pr_{H_0}\left(T \leq t_{\text{obs}}\right).
\]</span></p>
<ul>
<li>For a two-tailed test (where extreme in either direction counts):</li>
</ul>
<p><span class="math display">\[
\text{p-value} = \Pr_{H_0}\left(\left|T\right| \geq t_{\text{obs}}\right),
\]</span> ,i.e.&nbsp;the probability of <span class="math inline">\(T\)</span> being as far or farther from the null hypothesis expectation as the observed, in either direction. This can often be computed as twice the one-tailed probability for the tail that <span class="math inline">\(t_{\text{obs}}\)</span> lies in.</p>
<p>In less symbolic language: we locate our observed statistic on the null distribution and see what fraction (or area) of the null distribution lies at least as extreme. The more extreme <span class="math inline">\(t_{\text{obs}}\)</span> is, the smaller this tail area will be, and thus the smaller the p-value. Interpreting the p-value: If the p-value is, say, 0.03, that means “if <span class="math inline">\(H_0\)</span> were true, there is a 3% chance of seeing a result as extreme as this.” A small p-value indicates the observed data are unlikely under <span class="math inline">\(H_0\)</span>, which is why we reject <span class="math inline">\(H_0\)</span> when p is below our α threshold. Note that <em>unlikely under</em> <span class="math inline">\(H_0\)</span> does not automatically imply <em><span class="math inline">\(H_1\)</span> is true</em> – it simply raises skepticism about <span class="math inline">\(H_0\)</span>. (It could be a rare fluke, after all; in the long run, α proportion of true nulls will yield small p-values by chance.)</p>
<p>To reinforce proper understanding, remember: <strong>The p-value is computed under the assumption that <span class="math inline">\(H_0\)</span> is true</strong>. . It is not <span class="math inline">\(P(H_0\text{ is true} \mid \text{data})\)</span> and not <span class="math inline">\(P(H_1\text{ is true} \mid \text{data})\)</span>. It’s about the data’s compatibility with <span class="math inline">\(H_0\)</span>. A low p-value says “this data would be rare if <span class="math inline">\(H_0\)</span> is true,” whereas a high p-value says “this data is quite normal if <span class="math inline">\(H_0\)</span> is true.”</p>
<p>If p &lt; α, we call the result <strong>statistically significant</strong>, and we <em>reject</em> <span class="math inline">\(H_0\)</span>. If p ≥ α, the result is not significant, and we <em>do not reject</em> <span class="math inline">\(H_0\)</span>.</p>
<p>For example, at α = 0.05:</p>
<ul>
<li>p = 0.001 -&gt; significant (strong evidence against <span class="math inline">\(H_0\)</span>),</li>
<li>p = 0.04 -&gt; significant (evidence against <span class="math inline">\(H_0\)</span>),</li>
<li>p = 0.08 -&gt; not significant (data are not sufficiently unusual under <span class="math inline">\(H_0\)</span>).</li>
</ul>
<p>One more point: When test statistics are continuous, if <span class="math inline">\(H_0\)</span> is true and all assumptions hold, p-values are <strong>uniformly distributed</strong> between 0 and 1. This means that under <span class="math inline">\(H_0\)</span>, any p-value is equally likely. As a consequence, if <span class="math inline">\(H_0\)</span> is true, the probability of p ≤ 0.05 is 0.05 (which aligns with our Type&nbsp;I error α). This uniformity is a mathematical fact that ensures our testing procedure is calibrated. If p-values weren’t uniform under <span class="math inline">\(H_0\)</span>, a threshold like 0.05 would not correspond exactly to a 5% false positive rate. (This holds for continuous distributions; for discrete cases like the binomial test, p-values have a discrete distribution but still will not be biased toward low values under <span class="math inline">\(H_0\)</span>.)</p>
</section>
<section id="critical-values-and-the-relationship-to-p-values" class="level2">
<h2 class="anchored" data-anchor-id="critical-values-and-the-relationship-to-p-values">Critical Values and the Relationship to P-Values</h2>
<p>There are two equivalent ways to conduct most hypothesis tests:</p>
<ul>
<li><p><strong>Critical value approach</strong>: Determine the cutoff value of the test statistic beyond which <span class="math inline">\(H_0\)</span> will be rejected. This cutoff is chosen so that if <span class="math inline">\(H_0\)</span> is true, the probability the test statistic falls beyond the cutoff is α. For instance, in a right-tailed test, the critical value <span class="math inline">\(c\)</span> might be the 95th percentile of the null distribution (so <span class="math inline">\(P_{H_0}(T \ge c) = 0.05\)</span>). We reject <span class="math inline">\(H_0\)</span> if the observed <span class="math inline">\(T \ge c\)</span>.</p></li>
<li><p><strong>P-value approach</strong>: Calculate the p-value for the observed test statistic. Reject <span class="math inline">\(H_0\)</span> if p-value ≤ α.</p></li>
</ul>
<p>These two approaches lead to the same conclusions. The critical value is essentially the boundary where p-value = α. For example, if the 95th percentile of the null distribution is <span class="math inline">\(c\)</span>, then observing <span class="math inline">\(T=c\)</span> yields p-value = 0.05 (for a right-tailed test). Observing <span class="math inline">\(T &gt; c\)</span> yields p &lt; 0.05, and <span class="math inline">\(T &lt; c\)</span> yields p &gt; 0.05.</p>
<p><strong>Example (critical value vs p-value)</strong>: Suppose <span class="math inline">\(T \sim N(0,1)\)</span> under <span class="math inline">\(H_0\)</span> (a Z-test). For a two-tailed test at α = 0.05, the critical values are approximately ±1.96 (because 2.5% of the distribution is above 1.96 and 2.5% is below -1.96). So:</p>
<ul>
<li><p>Critical region: reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(T &gt; 1.96\)</span> or <span class="math inline">\(T &lt; -1.96\)</span>.</p></li>
<li><p>If our observed <span class="math inline">\(T = 2.5\)</span>, this exceeds the critical value, so we reject. The p-value would be <span class="math inline">\(2 \times P(Z &gt; 2.5)\)</span> (two-tailed) which is about 0.0124, indeed ≤ 0.05.</p></li>
<li><p>If observed <span class="math inline">\(T = 1.0\)</span>, this does not exceed 1.96, so we fail to reject. The p-value would be <span class="math inline">\(2 \times P(Z &gt; 1.0) ≈ 0.32\)</span>, which is &gt; 0.05.</p></li>
</ul>
<p>In summary, you can think of the p-value as the <em>area in the tail beyond the observed statisti</em>c, and α as the <em>area in the tail beyond the critical value</em>. If the observed stat is past the critical value, the tail area beyond it (p-value) will be smaller than α.</p>
</section>
<section id="obtaining-null-distributions-analytical-vs-simulation" class="level2">
<h2 class="anchored" data-anchor-id="obtaining-null-distributions-analytical-vs-simulation">Obtaining Null Distributions: Analytical vs Simulation</h2>
<p>To calculate p-values or critical values, we often need the null distribution. There are two main ways to get it:</p>
<p><strong>1.Analytical derivation (parametric approach)</strong>: Using theoretical probability distributions and assumptions about the data (e.g., normality, independence), we derive the distribution of the test statistic under <span class="math inline">\(H_0\)</span>. Classic examples:</p>
<ul>
<li><p>Use the Binomial<span class="math inline">\((n,p)\)</span> distribution for count of successes under <span class="math inline">\(H_0\)</span>.</p></li>
<li><p>Use the <span class="math inline">\(t\)</span> distribution for a t-statistic under <span class="math inline">\(H_0\)</span> (when data are normal or <span class="math inline">\(n\)</span> is large).</p></li>
<li><p>Use the <span class="math inline">\(F\)</span> distribution for an ANOVA F-statistic under <span class="math inline">\(H_0\)</span>.</p></li>
<li><p>Use the <span class="math inline">\(\chi^2\)</span> distribution for a chi-square statistic under <span class="math inline">\(H_0\)</span>.</p></li>
</ul>
<p>These derivations come from probability theory and often involve assumptions (like the data following certain distributions, or large-sample approximations). When conditions are met, the analytical approach is very convenient and fast.</p>
<p><strong>2. Simulation or resampling (nonparametric approach)</strong>: When the null distribution is complex or unknown, we can simulate it. This could be:</p>
<ul>
<li><p><strong>Monte Carlo simulation</strong>: Generate many random datasets under <span class="math inline">\(H_0\)</span> (using a known or estimated model) and compute the test statistic for each to see its empirical distribution.</p></li>
<li><p><strong>Permutation (randomization) tests</strong>: If we have a real dataset, we can create new datasets that satisfy <span class="math inline">\(H_0\)</span> by randomly shuffling or resampling the data. We then calculate the test statistic for each permuted dataset. The distribution of these statistics approximates the null distribution without relying on a formula.</p></li>
</ul>
<p>Simulation methods are very useful if, for example, the theoretical null distribution is unknown or too hard to derive, or if we distrust the model assumptions required for the parametric approach. They are computationally heavier but increasingly feasible with modern computing. Permutation tests (a form of simulation) are particularly powerful for preserving the exact data characteristics while enforcing <span class="math inline">\(H_0\)</span> – for instance, shuffling labels in a treatment vs control experiment breaks any real difference (satisfying <span class="math inline">\(H_0\)</span>), but keeps the data values themselves intact. I will cover permutation tests in detail later in the series, as they form the basis of permutation-based FWER correction.</p>
<p>For now, I will illustrate obtaining a null distribution by simulation with a simple example in R.</p>
</section>
<section id="example-generating-a-null-distribution-via-simulation-and-comparing-to-theory" class="level2">
<h2 class="anchored" data-anchor-id="example-generating-a-null-distribution-via-simulation-and-comparing-to-theory">Example: Generating a Null Distribution via Simulation (and Comparing to Theory)</h2>
<p>Consider again the coin-flip scenario, but now with a larger number of flips to get a smoother distribution. Suppose <span class="math inline">\(H_0\)</span>: coin is fair (<span class="math inline">\(p=0.5\)</span>), and we plan to flip <span class="math inline">\(n=100\)</span> times. Our test statistic is the number of heads in 100 flips. We know analytically that under <span class="math inline">\(H_0\)</span>, <span class="math inline">\(T \sim \text{Binomial}(100, 0.5)\)</span>.</p>
<p>Let’s obtain the null distribution in two ways: (a) analytical formula, and (b) Monte Carlo simulation of many experiments. I will then use it to compute a p-value for a specific observed outcome (say we observed 60 heads out of 100).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span>          <span class="co"># number of coin flips</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>p_null <span class="ot">&lt;-</span> <span class="fl">0.5</span>     <span class="co"># probability of heads under H0</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>observed <span class="ot">&lt;-</span> <span class="dv">60</span>    <span class="co"># suppose this is the observed number of heads in the real experiment</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># (a) Analytical p-value calculation (one-tailed for illustration: H1 is bias toward heads)</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>p_value_theory <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">pbinom</span>(observed <span class="sc">-</span> <span class="dv">1</span>, <span class="at">size =</span> n, <span class="at">prob =</span> p_null)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>p_value_theory  <span class="co"># P(X &gt;= 60) under Binomial(100, 0.5)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.02844397</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># (b) Simulation: generate many experiments under H0</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>reps <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>sim_counts <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(reps, <span class="at">size =</span> n, <span class="at">prob =</span> p_null)  <span class="co"># simulate 10,000 experiments</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Empirical p-value from simulation (fraction of experiments with &gt;= 60 heads)</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>p_value_sim <span class="ot">&lt;-</span> <span class="fu">mean</span>(sim_counts <span class="sc">&gt;=</span> observed)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>p_value_sim</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0254</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check that simulation p-value ~ theoretical p-value</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abs</span>(p_value_sim <span class="sc">-</span> p_value_theory)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.003043967</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the null distribution from simulation</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(sim_counts, <span class="at">breaks =</span> <span class="dv">20</span>, <span class="at">col =</span> <span class="st">"skyblue"</span>, <span class="at">main =</span> <span class="st">"Null distribution of heads count (100 flips, p=0.5)"</span>,</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Number of heads in 100 flips"</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> observed, <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Let’s break down what I did:</p>
<ul>
<li><p>I set <code>observed &lt;- 60</code> as an example outcome (60 heads out of 100 flips).</p></li>
<li><p>The theoretical one-tailed p-value (for the hypothesis of bias towards more heads) is computed as <code>1 - pbinom(59, 100, 0.5)</code>. This gives <span class="math inline">\(P(X \ge 60)\)</span> for <span class="math inline">\(X \sim \text{Binomial}(100,0.5)\)</span>.</p></li>
<li><p>Finally, I plotted a histogram of the simulated null distribution and drew a red line at the observed value 60.</p></li>
</ul>
<p>If you run this, you should see that <code>p_value_theory</code> and <code>p_value_sim</code> are very close (they’ll differ by a small random error on the order of <span class="math inline">\(10^{-3}\)</span> or so). For instance, you might get something like <code>p_value_theory ≈ 0.0284</code> and <code>p_value_sim ≈ 0.0291</code> – these are essentially the same, confirming that our simulation is accurately capturing the binomial distribution.</p>
<p>Empirical null distribution of the test statistic (number of heads in 100 flips) under the <span class="math inline">\(H_0\)</span> that the coins are exactly fair: The histogram shows the outcomes of 10,000 simulated fair coin experiments, each with 100 flips. The distribution is roughly bell-shaped, centered around near 50 heads. The red line marks the observed result (60 heads) from a single experiment. The p-value for the observation is the proportion of the null distribution that lies to the right of this red line (the shaded area beyond 60). In this example, the p-value is about 0.03, meaning there is a ~3% chance of seeing 60 or more heads if the coin is truly fair (or, more specifically, if the true expected value of the experiment is 50).</p>
<p>As expected, the null distribution is centered at 50 (when the coin is fair, on average half the flips are heads). Getting 60 heads is somewhat uncommon under <span class="math inline">\(H_0\)</span> (only ~3% of random fair-coins flips achieved that or more in our simulation). If we were testing <span class="math inline">\(H_0\)</span> at α = 0.05 with the alternative hypothesis “biased toward heads” (one-tailed), we would reject <span class="math inline">\(H_0\)</span> since p ≈ 0.03 &lt; 0.05. If our alternative was two-tailed (detecting any bias), we would consider both tails (≤40 heads or ≥60 heads) which roughly doubles the p-value to ~0.06; in that two-tailed case, 60 heads is actually borderline and would not be significant at the 0.05 level (because while 60 is unusual, so would an equally extreme deficit of heads – our observed outcome is only extreme on the high side).</p>
<p>This example illustrates how we use null distributions to obtain p-values, and how simulation can validate or substitute for analytical calculations. In more complex situations where we can’t write down a formula for the null distribution, we can rely on simulation or permutation to approximate it. The histogram also gives a visual intuition: most outcomes cluster around 50; 60 is out in the tail (hence p ~ 0.03 is the area of that tail).</p>
</section>
<section id="the-role-of-null-distributions-in-multiple-comparisons" class="level2">
<h2 class="anchored" data-anchor-id="the-role-of-null-distributions-in-multiple-comparisons">The Role of Null Distributions in Multiple Comparisons</h2>
<p><em>(A brief forward-looking note)</em>: When we perform <strong>multiple hypothesis tests</strong> (common in fields like neuroimaging, where we often test thousands of voxels for activation differences), the null distribution of the <em>maximum test statistic</em> or other aggregate becomes important for controlling the family-wise error rate. Permutation methods often involve simulating the null distribution for the <em>entire set of tests</em> by shuffling data labels, and then using the distribution’s quantiles to define corrected critical values that ensure the overall Type&nbsp;I error (FWER) is controlled. In later posts, we will see how the fundamentals from Part&nbsp;1 and Part&nbsp;2 come together to address those scenarios. Specifically, we will use permutation-generated null distributions to adjust for multiple comparisons (FWER), ensuring that the chance of any false positive across many tests stays at a desired level (like 5%).</p>
<p>Understanding null distributions and p-values is a critical step in that journey. You should now have a solid grasp of what p-values represent, how to obtain them, and how to interpret them in the context of hypothesis tests. In the next part of this series, I will delve into multiple testing and error rates (including FWER and the false discovery rate) and introduce permutation-based approaches to control these error rates. I’ll show how permutation tests can be applied in a neuroscience context (e.g.&nbsp;analyzing EEG or fMRI data) to make robust inferences while accounting for the multiplicity of comparisons.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>